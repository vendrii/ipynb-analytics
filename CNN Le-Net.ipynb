{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Le-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.1.4\n"
     ]
    }
   ],
   "source": [
    "!jupyter notebook --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!conda install numpy --force-reinstall\n",
    "!conda install scipy --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load module \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set seed (random for reproducability)\n",
    "SEED = 8989\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backend.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find mean and standard deviation across training set for normalize the data.\n",
    "ROOT = '.data'\n",
    "\n",
    "train_data = datasets.MNIST(root=ROOT,\n",
    "                            train=True,\n",
    "                            download=True)\n",
    "\n",
    "mean = train_data.data.float().mean() / 255\n",
    "std = train_data.data.float().std() / 255\n",
    "\n",
    "print(f'Calculated mean: {mean}')\n",
    "print(f'Calculated std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train and test transforms\n",
    "train_transforms = transforms.Compose([\n",
    "                            transforms.RandomRotation(5, fill=(0,)),\n",
    "                            transforms.RandomCrop(28, padding=2),\n",
    "                            tranforms.ToTensor(),\n",
    "                            transforms.Normalize(mean=[mean], std=[std])\n",
    "                                    ])\n",
    "test_transforms = transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean=[mean], std=[std])\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load training and testing data\n",
    "train_data = datasets.MNIST(root=ROOT,\n",
    "                            train=True,\n",
    "                            download=True,\n",
    "                            transform=train_transforms)\n",
    "\n",
    "test_data = datasets.MNIST(root=ROOT,\n",
    "                           train=False,\n",
    "                           download=True,\n",
    "                           transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create validation from 10% Training Data\n",
    "VALID_RATIO = 0.9\n",
    "\n",
    "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, valid_data = data.random_split(train_data,\n",
    "                                           [n_train_examples, n_valid_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deepcopy for copy set validation to set the validation static for better resemble testing\n",
    "valid_data = copy.deepcopy(valid_data)\n",
    "valid_data.dataset.transform = test_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking number of training, validation, testing examples\n",
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting batch size into 64 and only shuffle the training data each epoch\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iterator = data.DataLoader(train_data,\n",
    "                                 shuffle=True,\n",
    "                                 batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_iterator = data.DataLoader(valid_data,\n",
    "                                 batch_size=BATCH_SIZE)\n",
    "\n",
    "test_iterator = data.DataLoader(test_data,\n",
    "                                batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The plot_filter function takes in a batch of images and a two-dimensional filter and plots the output of that filter applied to all of the images.\n",
    "\n",
    "def plot_filter(images, filter):\n",
    "\n",
    "    images = images = torch.cat([i.unsqueeze(0) for i in images],\n",
    "                                dim=0).cpu()\n",
    "    filter = torch.FloatTensor(filter).unsqueeze(0).unsqueeze(0).cpu()\n",
    "\n",
    "    n_images = images.shape[0]\n",
    "\n",
    "    filtered_images = F.conv2d(images, filter)\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 5))\n",
    "\n",
    "    for i in range(n_images):\n",
    "\n",
    "        ax = fig.add_subplot(2, n_images, i+1)\n",
    "        ax.imshow(images[i].squeeze(0), cmap='bone')\n",
    "        ax.set_title('Original')\n",
    "        ax.axis('off')\n",
    "\n",
    "        image = filtered_images[i].squeeze(0)\n",
    "\n",
    "        ax = fig.add_subplot(2, n_images, n_images+i+1)\n",
    "        ax.imshow(image, cmap='bone')\n",
    "        ax.set_title('Filtered')\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick 5 images\n",
    "N_IMAGES = 5\n",
    "\n",
    "images = [image for image, label in [test_data[i] for i in range(N_IMAGES)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the image more clear using filter\n",
    "#### make the image more pop and easy to detect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizontal filter\n",
    "#### filtered images that the highest values (the whitest pixels) of the filtered image are where there is a horizontal line that is black on top and white below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_filter = [[-1, -2, -1],\n",
    "                     [ 0,  0,  0],\n",
    "                     [ 1,  2,  1]]\n",
    "\n",
    "plot_filter(images, horizontal_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swapping the first and last rows of the above filter\n",
    "horizontal_filter = [[ 1,  2,  1],\n",
    "                     [ 0,  0,  0],\n",
    "                     [-1, -2, -1]]\n",
    "\n",
    "plot_filter(images, horizontal_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertical filter\n",
    "### Vertical filter that are black on the left and white on the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_filter = [[-1, 0, 1],\n",
    "                   [-2, 0, 2],\n",
    "                   [-1, 0, 1]]\n",
    "\n",
    "plot_filter(images, vertical_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap the left and right columns.\n",
    "vertical_filter = [[1, 0, -1],\n",
    "                   [2, 0, -2],\n",
    "                   [1, 0, -1]]\n",
    "\n",
    "plot_filter(images, vertical_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagonal filter\n",
    "### This one detects lines pointing towards the top right of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diagonal filter\n",
    "diagonal_filter = [[-2, -1, 0],\n",
    "                   [-1,  0, 1],\n",
    "                   [ 0,  1, 2]]\n",
    "\n",
    "plot_filter(images, diagonal_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that allows us to see the outputs of a pooling layer on a batch of images\n",
    "def plot_subsample(images, pool_type, pool_size):\n",
    "\n",
    "    images = torch.cat([i.unsqueeze(0) for i in images], dim=0).cpu()\n",
    "\n",
    "    if pool_type.lower() == 'max':\n",
    "        pool = F.max_pool2d\n",
    "    elif pool_type.lower() in ['mean', 'avg']:\n",
    "        pool = F.avg_pool2d\n",
    "    else:\n",
    "        raise ValueError(f'pool_type must be either max or mean, got: {pool_type}')\n",
    "\n",
    "    n_images = images.shape[0]\n",
    "\n",
    "    pooled_images = pool(images, kernel_size=pool_size)\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 5))\n",
    "\n",
    "    for i in range(n_images):\n",
    "\n",
    "        ax = fig.add_subplot(2, n_images, i+1)\n",
    "        ax.imshow(images[i].squeeze(0), cmap='bone')\n",
    "        ax.set_title('Original')\n",
    "        ax.axis('off')\n",
    "\n",
    "        image = pooled_images[i].squeeze(0)\n",
    "\n",
    "        ax = fig.add_subplot(2, n_images, n_images+i+1)\n",
    "        ax.imshow(image, cmap='bone')\n",
    "        ax.set_title('Subsampled')\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max pooling with a filter size of 2 (trying to heavy downsampled - reduces in size/resolution and in quality)\n",
    "plot_subsample(images, 'max', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase the size of the max pooling filter, the images get smaller and the quality gets worse\n",
    "plot_subsample(images, 'max', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average pooling\n",
    "plot_subsample(images, 'avg', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another average pooling\n",
    "plot_subsample(images, 'avg', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Model\n",
    "# after the pooling layer, we will get the exact same results if you apply the activation function before, however this means you will be applying your activation function to a larger number of inputs, increasing the computation required\n",
    "# Using the activation function after the image has been reduced in size means it will be applied to fewer inputs and thus use less computation\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,\n",
    "                               out_channels=6,\n",
    "                               kernel_size=5)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=6,\n",
    "                               out_channels=16,\n",
    "                               kernel_size=5)\n",
    "\n",
    "        self.fc_1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc_2 = nn.Linear(120, 84)\n",
    "        self.fc_3 = nn.Linear(84, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x = [batch size, 1, 28, 28]\n",
    "\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        # x = [batch size, 6, 24, 24]\n",
    "\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        # x = [batch size, 6, 12, 12]\n",
    "\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        # x = [batch size, 16, 8, 8]\n",
    "\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        # x = [batch size, 16, 4, 4]\n",
    "\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # x = [batch size, 16*4*4 = 256]\n",
    "\n",
    "        h = x\n",
    "\n",
    "        x = self.fc_1(x)\n",
    "\n",
    "        # x = [batch size, 120]\n",
    "\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc_2(x)\n",
    "\n",
    "        # x = batch size, 84]\n",
    "\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc_3(x)\n",
    "\n",
    "        # x = [batch size, output dim]\n",
    "\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the model\n",
    "OUTPUT_DIM = 10\n",
    "\n",
    "model = LeNet(OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining optimizer\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function (which will also apply the softmax activation function)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the device (to put our model and data on the GPU, if we have one)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place the model and criterion on the device\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to calculate accuracy\n",
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim=True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that performs a training epoch\n",
    "def train(model, iterator, optimizer, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for (x, y) in tqdm(iterator, desc=\"Training\", leave=False):\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred, _ = model(x)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that performs an evaluation epoch\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in tqdm(iterator, desc=\"Evaluating\", leave=False):\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that tells us how long an epoch takes\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing parameters which performed the best on the validation set and then evaluate our performance on the test set.\n",
    "EPOCHS = 20\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in trange(EPOCHS, desc=\"Epochs\"):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('tut2-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion, device)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examing the Model\n",
    "#### Examine our model by: plotting a confusion matrix, seeing which incorrect examples our model was most confident about, view our model's learned representations in two dimensions with PCA and t-SNE, and view the weights of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model's predictions across the test set\n",
    "def get_predictions(model, iterator, device):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            y_prob = F.softmax(y_pred, dim=-1)\n",
    "\n",
    "            images.append(x.cpu())\n",
    "            labels.append(y.cpu())\n",
    "            probs.append(y_prob.cpu())\n",
    "\n",
    "    images = torch.cat(images, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    probs = torch.cat(probs, dim=0)\n",
    "\n",
    "    return images, labels, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, probs = get_predictions(model, test_iterator, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the predicted labels from the model's predictions.\n",
    "pred_labels = torch.argmax(probs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "def plot_confusion_matrix(labels, pred_labels):\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    cm = confusion_matrix(labels, pred_labels)\n",
    "    cm = ConfusionMatrixDisplay(cm, display_labels=range(10))\n",
    "    cm.plot(values_format='d', cmap='Blues', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting confition plot\n",
    "plot_confusion_matrix(labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out which of our examples are correct\n",
    "corrects = torch.eq(labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the incorrect examples and sort them by descending confidence in their prediction\n",
    "incorrect_examples = []\n",
    "\n",
    "for image, label, prob, correct in zip(images, labels, probs, corrects):\n",
    "    if not correct:\n",
    "        incorrect_examples.append((image, label, prob))\n",
    "\n",
    "incorrect_examples.sort(reverse=True,\n",
    "                        key=lambda x: torch.max(x[2], dim=0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the examples the model got wrong and was most confident about\n",
    "def plot_most_incorrect(incorrect, n_images):\n",
    "\n",
    "    rows = int(np.sqrt(n_images))\n",
    "    cols = int(np.sqrt(n_images))\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    for i in range(rows*cols):\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "        image, true_label, probs = incorrect[i]\n",
    "        true_prob = probs[true_label]\n",
    "        incorrect_prob, incorrect_label = torch.max(probs, dim=0)\n",
    "        ax.imshow(image.view(28, 28).cpu().numpy(), cmap='bone')\n",
    "        ax.set_title(f'true label: {true_label} ({true_prob:.3f})\\n'\n",
    "                     f'pred label: {incorrect_label} ({incorrect_prob:.3f})')\n",
    "        ax.axis('off')\n",
    "    fig.subplots_adjust(hspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model is always trained to be incredibly confident with its predictions, so it's not unreasonable for it to be incredibly confident when it's wrong.\n",
    "\n",
    "N_IMAGES = 25\n",
    "\n",
    "plot_most_incorrect(incorrect_examples, N_IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representations Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_representations(model, iterator, device):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    outputs = []\n",
    "    intermediates = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in tqdm(iterator):\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            y_pred, h = model(x)\n",
    "\n",
    "            outputs.append(y_pred.cpu())\n",
    "            intermediates.append(h.cpu())\n",
    "            labels.append(y)\n",
    "\n",
    "    outputs = torch.cat(outputs, dim=0)\n",
    "    intermediates = torch.cat(intermediates, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "\n",
    "    return outputs, intermediates, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, intermediates, labels = get_representations(model,\n",
    "                                                     train_iterator,\n",
    "                                                     device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate PCA on the representations\n",
    "def get_pca(data, n_components=2):\n",
    "    pca = decomposition.PCA()\n",
    "    pca.n_components = n_components\n",
    "    pca_data = pca.fit_transform(data)\n",
    "    return pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print PCA Plot \n",
    "def plot_representations(data, labels, n_images=None):\n",
    "    if n_images is not None:\n",
    "        data = data[:n_images]\n",
    "        labels = labels[:n_images]\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    scatter = ax.scatter(data[:, 0], data[:, 1], c=labels, cmap='tab10')\n",
    "    handles, labels = scatter.legend_elements()\n",
    "    ax.legend(handles=handles, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pca_data = get_pca(outputs)\n",
    "plot_representations(output_pca_data, labels)\n",
    "# Result: classes are overlapped in one giant cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsetting data with t-SNE\n",
    "intermediate_pca_data = get_pca(intermediates)\n",
    "plot_representations(intermediate_pca_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tsne(data, n_components=2, n_images=None):\n",
    "    if n_images is not None:\n",
    "        data = data[:n_images]\n",
    "    tsne = manifold.TSNE(n_components=n_components, random_state=0)\n",
    "    tsne_data = tsne.fit_transform(data)\n",
    "    return tsne_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_IMAGES = 5_000\n",
    "\n",
    "output_tsne_data = get_tsne(outputs, n_images=N_IMAGES)\n",
    "plot_representations(output_tsne_data, labels, n_images=N_IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional layers\n",
    "intermediate_tsne_data = get_tsne(intermediates, n_images=N_IMAGES)\n",
    "plot_representations(intermediate_tsne_data, labels, n_images=N_IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagine_digit(model, digit, device, n_iterations=50_000):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    best_prob = 0\n",
    "    best_image = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for _ in trange(n_iterations):\n",
    "\n",
    "            x = torch.randn(32, 1, 28, 28).to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            preds = F.softmax(y_pred, dim=-1)\n",
    "\n",
    "            _best_prob, index = torch.max(preds[:, digit], dim=0)\n",
    "\n",
    "            if _best_prob > best_prob:\n",
    "                best_prob = _best_prob\n",
    "                best_image = x[index]\n",
    "\n",
    "    return best_image, best_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIGIT = 3\n",
    "\n",
    "best_image, best_prob = imagine_digit(model, DIGIT, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Best Image Probability\n",
    "print(f'Best image probability: {best_prob.item()*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(best_image.squeeze(0).cpu().numpy(), cmap='bone')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes a batch of images and multiple filters\n",
    "def plot_filtered_images(images, filters):\n",
    "\n",
    "    images = torch.cat([i.unsqueeze(0) for i in images], dim=0).cpu()\n",
    "    filters = filters.cpu()\n",
    "\n",
    "    n_images = images.shape[0]\n",
    "    n_filters = filters.shape[0]\n",
    "\n",
    "    filtered_images = F.conv2d(images, filters)\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "    for i in range(n_images):\n",
    "\n",
    "        ax = fig.add_subplot(n_images, n_filters+1, i+1+(i*n_filters))\n",
    "        ax.imshow(images[i].squeeze(0), cmap='bone')\n",
    "        ax.set_title('Original')\n",
    "        ax.axis('off')\n",
    "\n",
    "        for j in range(n_filters):\n",
    "            image = filtered_images[i][j]\n",
    "            ax = fig.add_subplot(n_images, n_filters+1, i+1+(i*n_filters)+j+1)\n",
    "            ax.imshow(image.numpy(), cmap='bone')\n",
    "            ax.set_title(f'Filter {j+1}')\n",
    "            ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_IMAGES = 5\n",
    "\n",
    "images = [image for image, label in [test_data[i] for i in range(N_IMAGES)]]\n",
    "filters = model.conv1.weight.data\n",
    "\n",
    "plot_filtered_images(images, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the actual filters\n",
    "plot_filtered_images([best_image], filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting more zoom about patterns visible\n",
    "def plot_filters(filters):\n",
    "\n",
    "    filters = filters.cpu()\n",
    "\n",
    "    n_filters = filters.shape[0]\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "    for i in range(n_filters):\n",
    "\n",
    "        ax = fig.add_subplot(1, n_filters, i+1)\n",
    "        ax.imshow(filters[i].squeeze(0), cmap='bone')\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_filters(filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
